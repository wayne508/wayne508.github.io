<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ucore源码分析：bootloader]]></title>
    <url>%2F2015%2F08%2F20%2Fucore%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%9Abootloader%2F</url>
    <content type="text"><![CDATA[1 总述bootloader的程序存放在硬盘的第一个扇区（512B）。BIOS程序会将bootloader加载到内存0x7c00处，并跳转到这里执行。 bootloader的主要作用： 打开A20地址线，使CPU进入32位实模式； 探测物理内存大小； 设置CR0，进入32位保护模式； 加载内核镜像，把控制权交给内核。 2 准备 进入bootloader后，为了后向兼容，此时的CPU是16位模式（20根地址线，16位地址模式），20-31的地址线为0。此时的汇编代码应该有“.code16”前缀，表示16位模式。 在bootloader执行过程中，必须关闭中断，将数据段、附加段、堆栈段的段寄存器设置为0。 123456789.code16 # Assemble for 16-bit mode cli # Disable interrupts cld # String operations increment # Set up the important data segment registers (DS, ES, SS). xorw %ax, %ax # Segment number zero movw %ax, %ds # -&gt; Data Segment movw %ax, %es # -&gt; Extra Segment movw %ax, %ss # -&gt; Stack Segment 3 打开A203.1 背景为了兼容16位地址模式，32位CPU使用键盘控制器（8042控制器）的一个控制线（即A20控制线）来控制20-31位地址线的打开关闭。当A20控制线打开时可以使用20-31的地址线。而当A20 关闭时20-31的地址线全部为0。 3.2 8042控制器8042控制器内部拥有4个8位寄存器：状态寄存器、输出寄存器、输入寄存器、控制寄存器，对外通过两个I/O端口：0x64（命令端口）、0x60（数据端口）进行通信。 状态寄存器各位的定义如下： Bit7: 从键盘获得的数据奇偶校验错误 Bit6: 接收超时，置1 Bit5: 发送超时，置1 Bit4: 为1，键盘没有被禁止。为0，键盘被禁止。 Bit3: 为1，输入缓冲器中的内容为命令，为0，输入缓冲器中的内容为数据。 Bit2: 系统标志，加电启动置0，自检通过后置1 Bit1: 输入缓冲器满置1，i8042 取走后置0 BitO: 输出缓冲器满置1，CPU读取后置0 读写0x64和0x60的含义： 读取0x64端口时，返回状态寄存器的内容，可以判断8042控制器的忙闲状态； 写0x64端口时，一般写入操作命令。 读写0x60端口一般都跟在写0x64端口后，主要作用是读取发送操作命令后控制器的响应，或者写入操作命令需要的参数。 举个例子，如果要读取8042的控制寄存器的内容，需要发送20h命令，控制器就会把结果放在输出缓存器中等待CPU取走，接下来读取0x60端口读取内容；如果要写控制寄存器的内容，要发送60h命令，接下来将要设置的内容通过0x60端口写入。 但需要注意的是，无论是通过哪个端口（0x60、0x64）写入数据，都需要等待8042的输入缓存为空，否则就会冲掉上次的输入。判断输入缓存为空只需要判断状态寄存器的第2位是否为0（见状态寄存器的Bit1位）。 3.3 A20使能A20控制线是8042输出端口的第2位，只要设置该输出端口为1，就可以打开A20。写输出端口的命令是0xD1。那么整个流程可以描述为：1）等待输入缓存为空；2）从0x64端口写入0xD1命令；3）等待输入缓存为空；4）从0x60端口写入要设置的数据。 12345678910111213141516seta20.1: inb $0x64, %al # 读取状态寄存器 testb $0x2, %al # 判断输入缓存是否为空 jnz seta20.1 # 0xd1表示写输出端口命令，参数随后通过0x60端口写入 movb $0xd1, %al outb %al, $0x64 # 等待8042将输入命令取走seta20.2: inb $0x64, %al # Wait for not busy(8042 input buffer empty). testb $0x2, %al jnz seta20.2 # 通过0x60写入数据 11011111 movb $0xdf, %al # 0xdf -&gt; port 0x60 outb %al, $0x60 # 0xdf = 11011111, means set P2&apos;s A20 bit(the 1 bit) to 1 4 探测物理内存分布内核在管理内存前，需要知道物理内存的分布情况，哪些部分可以使用，哪些部分不能使用。内存分布情况可以通过BIOS中断来获取，具体就是INT 15h，参数eax为0xe820。 在调用INT 15h中断获取内存分布情况时，需要设置一些输入参数： 设置eax为0xE820 es:edi指向缓存区，缓存返回的内存分布描述符（Address Range Descriptor），表示内存段的状态。 ecx存放返回数据的大小，也就是内存分布描述符的大小，一般BIOS总是返回20字节 edx的值为0x534d4150，也就是“SMAP”的ASCII码。 输出： CF为1表示出现错误，否则无错 eax为“SMAP”的ASCII码，用于验证BIOS的返回是否正确。 es:di：返回内存分布描述符的地址，与输入值一样 ebx：返回获取下一描述符的后续值，作为下次中断的输入值。如果为0，则表示所有描述符获取完毕。 我们可以利用INT 15h获取到多个内存分布描述符。在ucore中，这些内存分布描述符存放在连续的内存空间中，也就是一个数组中，这个数组的起始地址为0x8004；而这个数组的长度存放在0x8000-0x8003的四字节内存中，作为整形使用。在kern/mm/memlayout.h中确实定义了等价的结构体e820map来表示这段内存：12345678struct e820map &#123; int nr_map; # 4字节，表示描述符的数量 struct &#123; # 20字节的结构体 uint64_t addr; # 8字节，表示内存段的起始地址 uint64_t size; # 8字节，表示内存段的大小 uint32_t type; # 4字节，表示内存段的类型：保留或空闲 &#125; __attribute__((packed)) map[E820MAX]; # 这是一个结构体数组&#125;; 再回到如何利用INT 15h获取e820map的汇编代码吧： 123456789101112131415161718probe_memory: movl $0, 0x8000 # 0x8000-0x8003代表e820map中的nr_map，初始值为0 xorl %ebx, %ebx # ebx初始值设为0，以后每次的返回值作为输入 movw $0x8004, %di # 0x8004代表e820map中数组map的初始地址start_probe: movl $0xE820, %eax # 给eax赋值为E820，由于eax会被修改，所以这条语句放在循环中，重复赋值为E820 movl $20, %ecx movl $SMAP, %edx int $0x15 jnc cont movw $12345, 0x8000 # 出错后，将nr_map赋值为12345 jmp finish_probecont: addw $20, %di # 缓存区地址增加20字节，也就是数组的下一元素 incl 0x8000 # nr_map++ cmpl $0, %ebx jnz start_probe # 判断是否存在下一个内存分布描述符finish_probe: 5 进入保护模式将gdtdesc加载到gdtr。gdtdesc指向一块6字节内存，其中包含了全局描述符表（gdt）的位置和长度。 gdt和gdtdesc的内容：12345678gdt: SEG_NULLASM # null seg SEG_ASM(STA_X|STA_R, 0x0, 0xffffffff) # code seg for bootloader and kernel SEG_ASM(STA_W, 0x0, 0xffffffff) # data seg for bootloader and kernelgdtdesc: .word 0x17 # sizeof(gdt) - 1 .long gdt # address gdt 接下来设置cr0的PE位（第0位）为1，开启保护模式。此时全局描述符表开始起作用，其中代码段和数据段的段基址均为0，也就是说此时的虚拟地址和线性地址是相等的。由于此时也没有开启分页模式，线性地址也就是物理地址。最后通过一条长跳转指令，进入32位代码段。 12345lgdt gdtdescmovl %cr0, %eaxorl $CR0_PE_ON, %eaxmovl %eax, %cr0ljmp $PROT_MODE_CSEG, $protcseg 接下来设置个数据段的段选择子（代码段的段选择子在ljmp执行后自动设置好），设置堆栈空间为0-0x7C00。堆栈设置好以后就可以调用C函数了。最后调用bootmain函数，此函数的主要作用就是从硬盘读取内核并加载到内存中并执行。 6 加载内核这部分的代码在boot/bootmain.c中，主要功能是从硬盘中读取内核（ELF文件）并加载到内存中。 6.1 磁盘操作对磁盘的操作需要通过IDE接口实现。其中IDE主通道的IO地址为0x1F0-0x1F7，IDE次通道的IO地址为0x170-0x177。每个通道可以挂载两块硬盘。这里需要操作的是第一个通道的第一块硬盘。 对硬盘的读写有两种模式：CHS和LBA（logic block address）。CHS也就是通过柱面、磁头、扇区的方式读写硬盘，LBA就像内存一样，通过线性地址来访问磁盘。 下面介绍LBA的方式读取硬盘。 0x1F0 - 0x1F7的IO端口含义如下： 0x1f0: 读/写数据 0x1f1: 读取错误状态 0x1f2: 读/写的扇区数目 0x1f3: LBA的0-7位(相当于扇区) 0x1f4: LBA的8-15位（相当于柱面） 0x1f5: LBA的16-23位(相当于柱面) 0x1f6: bit7、bit5必须为1；bit6：0为CHS模式，1为LBA模式；bit4：0为主盘，1为从盘；bit3-0：LBA的27-24位。 0x1f7: 命令/状态寄存器。发送命令或读取状态。 状态寄存器的各位被设置的含义： Bit7: 控制器忙 Bit6: 正常运转（停止转动或出错，该位清零） Bit5: 控制器严重错误 Bit4: Overlapped Mode Service Request Bit3: 控制器发出来数据或者准备好接收数据 Bit0: 出错 那么操作硬盘的步骤具体如下： 等待硬盘控制器不忙 写入操作硬盘的参数：模式、地址、主从盘等 读/写数据 6.2 读取扇区ucore将读取扇区的操作封装在函数readsect中：123456789101112131415161718192021static void waitdisk(void) &#123; while ((inb(0x1F7) &amp; 0xC0) != 0x40) // 读取状态寄存器，等待空闲 /* do nothing */;&#125;/* 读取扇区号为secno的扇区到内存dst的地址中 */static void readsect(void *dst, uint32_t secno) &#123; waitdisk(); outb(0x1F2, 1); // 读取扇区数为1 outb(0x1F3, secno &amp; 0xFF); // secno的0-7位 outb(0x1F4, (secno &gt;&gt; 8) &amp; 0xFF); // secno的8-15位 outb(0x1F5, (secno &gt;&gt; 16) &amp; 0xFF); // secno的16-23位 outb(0x1F6, ((secno &gt;&gt; 24) &amp; 0xF) | 0xE0); // secno的24-27位；0xE0=11100000b表示LBA模式、操作第一块硬盘 outb(0x1F7, 0x20); // 0x20读扇区命令 // wait for disk to be ready waitdisk(); insl(0x1F0, dst, SECTSIZE / 4);&#125; readseg函数调用了readsect函数，它的主要作用就是从内核偏移量为offset的地方读取count字节的数据，存放在起始位置为va的内存中。因为readsect是以整个扇区为单位读取，所以该函数读取的内容大于等于count。 12345678910111213141516static void readseg(uintptr_t va, uint32_t count, uint32_t offset) &#123; uintptr_t end_va = va + count; // 计算内存段可能的终止位置 // round down to sector boundary va -= offset % SECTSIZE; // 与扇区边界对齐 // translate from bytes to sectors; kernel starts at sector 1 uint32_t secno = (offset / SECTSIZE) + 1; // 内核起始位置在第一个扇区（第0个扇区为bootloader） // If this is too slow, we could read lots of sectors at a time. // We&apos;d write more to memory than asked, but it doesn&apos;t matter -- // we load in increasing order. for (; va &lt; end_va; va += SECTSIZE, secno ++) &#123; readsect((void *)va, secno); &#125;&#125; 6.3 ELF文件ELF文件是指可执行链接格式（Executable and Linking Format），最初由UNIX 系统实验室开发并发布的，作为应用程序二进制接口的一部分，也是Linux的主要可执行文件。 ELF文件有三种类型：1) 可重定位文件，也就是通常称的目标文件，后缀为.o。2) 共享文件：也就是通常称的库文件，后缀为.so。3) 可执行文件：本文主要考虑的文件格式。 文件格式： ELF头部：用来描述整个文件的组织 程序头部表：是一个结构数组，它的大小等于ELF头表中字段e_phnum定义的条目，结构描述一个段或其他系统准备执行该程序所需要的信息。 ucore中定义的ELF头结构：1234567891011121314151617struct elfhdr &#123; uint32_t e_magic; // must equal ELF_MAGIC uint8_t e_elf[12]; uint16_t e_type; // 1=relocatable, 2=executable, 3=shared object, 4=core image uint16_t e_machine; // 3=x86, 4=68K, etc. uint32_t e_version; // file version, always 1 uint32_t e_entry; // entry point if executable uint32_t e_phoff; // file position of program header or 0 uint32_t e_shoff; // file position of section header or 0 uint32_t e_flags; // architecture-specific flags, usually 0 uint16_t e_ehsize; // size of this elf header uint16_t e_phentsize; // size of an entry in program header uint16_t e_phnum; // number of entries in program header or 0 uint16_t e_shentsize; // size of an entry in section header uint16_t e_shnum; // number of entries in section header or 0 uint16_t e_shstrndx; // section number that contains section name strings&#125;; 其中： e_magic是0x7f、’E’、’L’、’F’，常数 e_elf[12]存放一些系统信息 e_phoff：程序头部表在文件中的位置 e_phnum：程序头部表中元素个数 e_entry：可执行程序入口 紧跟着ELF头部的就是程序头部表，它是一个数组，数组项的结构定义如下： 12345678910struct proghdr &#123; uint32_t p_type; // loadable code or data, dynamic linking info,etc. uint32_t p_offset; // 对应的段在文件中的位置 uint32_t p_va; // 需要映射的虚拟地址 uint32_t p_pa; // 物理地址，没用 uint32_t p_filesz; // 段在文件中的大小 uint32_t p_memsz; // 段在内存中的大小 uint32_t p_flags; // 段的标志 uint32_t p_align; // 是否对齐&#125;; 加载内核就是根据程序头部表的内容，将所有代码段加载到对应的内存中，并从ELF头部的可执行入口执行程序。 首先bootloader将内核最开始4k的内容加载到内容64k的地方。这4k的内容包含了ELF头部和程序头部表的内容。 遍历程序头部表，根据每一项的内容，加载对应的段到内存中。 从ELF头部的e_entry项执行程序。 1234567891011121314151617181920212223242526272829void bootmain(void) &#123; readseg((uintptr_t)ELFHDR, SECTSIZE * 8, 0); // 读取4k到ELFHDR位置 // is this a valid ELF? if (ELFHDR-&gt;e_magic != ELF_MAGIC) &#123; goto bad; &#125; struct proghdr *ph, *eph; // load each program segment (ignores ph flags) ph = (struct proghdr *)((uintptr_t)ELFHDR + ELFHDR-&gt;e_phoff); //程序头部表起始位置 eph = ph + ELFHDR-&gt;e_phnum; //程序头部表终止位置 for (; ph &lt; eph; ph ++) &#123; // 加载段到地址p_va&amp;0xFFFFFF中。 readseg(ph-&gt;p_va &amp; 0xFFFFFF, ph-&gt;p_memsz, ph-&gt;p_offset); &#125; // call the entry point from the ELF header // note: does not return ((void (*)(void))(ELFHDR-&gt;e_entry &amp; 0xFFFFFF))();bad: outw(0x8A00, 0x8A00); outw(0x8A00, 0x8E00); /* do nothing */ while (1);&#125; 这里需要注意一点，段被加载到的物理内存对应的虚拟地址应该是ph-&gt;p_va，但这里是ph-&gt;p_va &amp; 0xFFFFFF，这是为什么？ 文件tools/kernel.ld是链接产生内核的ld脚本。从中可以看到代码段的起始虚拟地址是0xC0100000。内核实际被加载到了0xC0100000 &amp; 0xFFFFFF = 0x100000的物理地址中，也就是内存起始1M的地方。当前代码段和数据段的段基址均为0，且没有开启分页机制，虚拟地址等于物理地址。为了让内核正常运行，需要把虚拟地址0xC0100000映射到物理地址0x100000处。所以进入内核的第一件事就是重新设置gdt，设置代码段和数据段的段基址为-0xC0000000。这部分不在bootloader中，这里不详述了。 另外，为了正确进入内核入口地址时，也需要和0xFFFFFF相与：ELFHDR-&gt;e_entry &amp; 0xFFFFFF = ELFHDR-&gt;e_entry - 0xC0000000，这是内核入口的真正物理地址。 7 参考 http://wiki.osdev.org/%228042%22\_PS/2\_Controller “”8042” PS/2 Controller” http://www.uruk.org/orig-grub/mem64mb.html “Query System Address Map” http://wiki.osdev.org/ATA\_PIO\_Mode “ATA PIO Mode” 滕启明 “ELF文件格式分析” http://www.ibm.com/developerworks/cn/linux/l-excutff/ “UNIX/LINUX 平台可执行文件格式分析”]]></content>
      <tags>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于SDN的简单load balancer]]></title>
    <url>%2F2015%2F08%2F13%2F%E5%9F%BA%E4%BA%8ESDN%E7%9A%84%E7%AE%80%E5%8D%95load-balancer%2F</url>
    <content type="text"><![CDATA[起因最近在看一个SDN相关的课程，链接：http://www.csg.ethz.ch/education/lectures/ATCN/hs2014虽然只能看课件，但感觉讲的很不错。课程还附带了几个课后任务，任务说明很详细，可以跟着一步一步做。其中一个就是基于POX控制器写一个简单的load balancer的控制程序。本文主要记录整个实验过程以及一些想法。 POX基础 launch: launch函数用来完成加载模块的初始化工作，比如绑定各种事件响应函数，也可以在launch函数中注册其他类。 Connection Up事件：当交换机和控制器建立连接时，触发该事件。 connection.send()：connection指控制器与某交换机之间的连接，通过send()方法，控制器可以向该交换机发送OpenFlow信息。 ofp_flow_mod：OpenFlow信息，向交换机中安装流表。ofp_flow_mod包含一些值得关注的域：match对象、actions列表、priority、idle timeout、hard timeout。 ofp_match：ofp_flow_mod中的match对象，用来匹配数据包。比如要匹配MAC地址，就需要设置match对象的dl_src和dl_dst域。 ofp_action_output：首先这是一个action对象，可以添加到ofp_flow_mod的actions列表中，指示将数据包输出到某个端口或者一些特殊定义的端口，比如of.OFPP_FLOOD。 ofp_packet_out：控制器发给交换机的OpenFlow信息，指示交换机如何发送某个数据包。 问题实验中的网络拓扑是一个星型拓扑，一个交换机连着8个主机。其中前4个主机（h1-h4）相当于Clients，可以向作为Servers的后4个主机（h5-h8）发起请求。交换机被当作一个load balancer来平衡Clients与Servers之间的请求。Clients通过一个公共的Service IP发起请求，交换机相当于一个透明的代理，将请求分发到不同的Server端。分发策略通过简单的随机方式实现。 需求分析 首先，交换机作为服务的透明代理，它需要知道真正的4个server分别和自己的哪些端口相连，这才能将请求正确地分发到不同的Server端。所以交换机应该主动发送ARP请求，记录Server的MAC地址，以及所在的端口。为了尽量减少请求的等待时长，交换机与控制器建立连接后，控制器应该马上指示交换机发送ARP请求。 客户端通过一个公共的IP（Service IP）来访问服务，而实际可能访问的是某个server。为了建立客户端到server的连接，当客户端发送ARP请求Service IP的MAC地址时，交换机应该使用一个伪MAC回答（这里使用0A:00:00:00:00:01）。而且这时交换机应该记录下客户端IP对应的MAC地址以及输入端口，这样当服务器响应后，它才能正确地传输给客户端。 Server响应客户端前，会向客户端发送ARP请求，交换机应该以自己的伪MAC地址回答。 客户端向Service IP发起请求，如果是新出现的客户端IP地址，交换机应该将请求随机定向到某个server上。这需要将数据包的目的IP地址和目的MAC地址重写为server的IP地址和MAC地址。同时源MAC地址为客户端的MAC地址，需要改写为交换机的伪MAC地址。 服务器向客户端响应时，交换机应该将源IP地址修改为Service IP地址，将源MAC地址改为交换机的伪MAC地址。同时将目的MAC地址改为正确的客户端MAC地址。 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160from pox.core import corefrom pox.openflow import *import pox.openflow.libopenflow_01 as offrom pox.lib.packet.arp import arpfrom pox.lib.packet.ethernet import ethernet, ETHER_BROADCASTfrom pox.lib.packet.ipv4 import ipv4from pox.lib.addresses import EthAddr, IPAddrlog = core.getLogger()import timeimport randomclass SimpleLoadBalancer(object): def __init__(self, service_ip, server_ips = []): #initialize core.openflow.addListeners(self) self.service_ip = service_ip self.server_ips = server_ips self.server_ip2mac = &#123;&#125; self.mac2port = &#123;&#125; self.ip2mac = &#123;&#125; self.client2server = &#123;&#125; def _handle_ConnectionUp(self, event): #new switch connection self.lb_mac = EthAddr("0A:00:00:00:00:01") #fake mac of load balancer self.connection = event.connection for server_ip in self.server_ips: self.send_proxied_arp_request(self.connection, server_ip) def update_lb_mapping(self, client_ip): #update load balancing mapping rnd = random.randint(0, len(self.server_ip2mac)-1) server_ip = self.server_ip2mac.keys()[rnd] return server_ip def send_proxied_arp_reply(self, packet, connection, outport, requested_mac): r = arp() r.opcode = arp.REPLY r.hwsrc = requested_mac r.hwdst = packet.src r.protosrc = packet.next.protodst r.protodst = packet.next.protosrc e = ethernet(type=ethernet.ARP_TYPE, src=self.lb_mac, dst=packet.src) e.set_payload(r) log.debug("Load balancer reply to %s's ARP \"%s is at %s\"" % (r.protodst, r.protosrc, r.hwsrc)) msg = of.ofp_packet_out() msg.data = e.pack() msg.actions.append(of.ofp_action_output(port=outport)) connection.send(msg) def send_proxied_arp_request(self, connection, ip): r = arp() r.opcode = arp.REQUEST r.hwsrc = self.lb_mac r.hwdst = ETHER_BROADCAST r.protosrc = self.service_ip r.protodst = ip e = ethernet(type=ethernet.ARP_TYPE, src=self.lb_mac, dst=ETHER_BROADCAST) e.set_payload(r) msg = of.ofp_packet_out() msg.data = e.pack() msg.actions.append(of.ofp_action_output(port=of.OFPP_FLOOD)) log.info("Load balancer ARPing for %s's MAC" % ip) connection.send(msg) def install_flow_rule_client_to_server(self, connection, outport, client_ip, server_ip, buffer_id=of.NO_BUFFER): match = of.ofp_match() match.dl_type = ethernet.IP_TYPE match.nw_src = client_ip match.nw_dst = self.service_ip msg = of.ofp_flow_mod() msg.match = match msg.buffer_id = buffer_id msg.idle_timeout = 10 server_mac = self.server_ip2mac[server_ip] msg.actions.append(of.ofp_action_dl_addr.set_src(self.lb_mac)) msg.actions.append(of.ofp_action_dl_addr.set_dst(server_mac)) msg.actions.append(of.ofp_action_nw_addr.set_dst(server_ip)) msg.actions.append(of.ofp_action_output(port=outport)) log.info("Installing flow rule for client %s to server %s" % (client_ip, server_ip)) connection.send(msg) def install_flow_rule_server_to_client(self, connection, outport, server_ip, client_ip, buffer_id=of.NO_BUFFER): match = of.ofp_match() match.dl_type = ethernet.IP_TYPE match.nw_src = server_ip match.nw_dst = client_ip msg = of.ofp_flow_mod() msg.match = match msg.buffer_id = buffer_id msg.idle_timeout = 10 client_mac = self.ip2mac[client_ip] msg.actions.append(of.ofp_action_nw_addr.set_src(self.service_ip)) msg.actions.append(of.ofp_action_dl_addr.set_src(self.lb_mac)) msg.actions.append(of.ofp_action_dl_addr.set_dst(client_mac)) msg.actions.append(of.ofp_action_output(port=outport)) log.info("Installing flow rule for server %s to client %s" % (server_ip, client_ip)) connection.send(msg) def _handle_PacketIn(self, event): packet = event.parsed connection = event.connection inport = event.port self.mac2port[packet.src] = inport if packet.type == packet.ARP_TYPE: r = packet.next if r.opcode == r.REQUEST: if r.protodst == self.service_ip: log.info("%s ARPing for %s's MAC" % (str(r.protosrc), str(self.service_ip))) self.send_proxied_arp_reply(packet, connection, inport, self.lb_mac) # server请求client 地址 elif r.protosrc in self.server_ips and r.protodst not in self.server_ips: log.info("Server %s ARPing for client %s's MAC" % (r.protosrc, r.protodst)) self.send_proxied_arp_request(connection, r.protodst) self.send_proxied_arp_reply(packet, connection, inport, self.lb_mac) elif r.opcode == r.REPLY: # load balancer请求server ip的arp响应 if r.protosrc in self.server_ips and r.protodst == self.service_ip: log.info("Server %s reply to load balancer's ARP \"%s is at %s\"" % (r.protosrc, r.protosrc, r.hwsrc)) self.server_ip2mac[r.protosrc] = r.hwsrc # client回复load balancer的arp请求 elif r.protosrc not in self.server_ips and r.protodst == self.service_ip: log.info("Client %s reply to load balancer's ARP \"%s is at %s\"" % (r.protosrc, r.protosrc, r.hwsrc)) self.ip2mac[r.protosrc] = packet.src elif packet.type == ethernet.IP_TYPE: ip = packet.next if ip.dstip == self.service_ip: if ip.srcip not in self.server_ips: # 客户端向service发起的请求 server_ip = self.update_lb_mapping(ip.srcip) server_mac = self.server_ip2mac[server_ip] outport = self.mac2port[server_mac] buffer_id = event.ofp.buffer_id log.debug("client to server port: %s" % outport) self.install_flow_rule_client_to_server(connection, outport, ip.srcip, server_ip, buffer_id) elif ip.srcip in self.server_ips and ip.dstip not in self.server_ips: client_mac = self.ip2mac.get(ip.dstip) if not client_mac: self.send_proxied_arp_request(connection, ip.dstip) return outport = self.mac2port[client_mac] log.debug("client to server port: %s" % outport) self.install_flow_rule_server_to_client(connection, outport, ip.srcip, ip.dstip) else: log.info("Unknown Packet type: %s" % packet.type) return return#launch application with following arguments:#ip: public service ip, servers: ip addresses of servers (in string format)def launch(ip, servers): log.info("Loading Simple Load Balancer module") server_ips = servers.replace(","," ").split() server_ips = [IPAddr(x) for x in server_ips] service_ip = IPAddr(ip) core.registerNew(SimpleLoadBalancer, service_ip, server_ips)]]></content>
      <tags>
        <tag>sdn</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用]]></title>
    <url>%2F2015%2F07%2F09%2Fgit%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python监控网卡流量]]></title>
    <url>%2F2015%2F06%2F09%2Fpython%E7%9B%91%E6%8E%A7%E7%BD%91%E5%8D%A1%E6%B5%81%E9%87%8F%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import timeimport threadingimport signalfrom datetime import datetimelast_in_bytes = Nonelast_out_bytes = Nonedef curr_traffic(inf): global last_in_bytes, last_out_bytes in_traffic, out_traffic = None, None with open('/proc/net/dev') as f: lines = f.readlines() for line in lines[2:]: line = line.strip() if line.startswith(inf + ':'): items = line.strip().split(':')[1].split() in_bytes, out_bytes = int(items[0]), int(items[8]) if last_in_bytes: in_traffic, out_traffic = in_bytes - last_in_bytes, out_bytes - last_out_bytes last_in_bytes, last_out_bytes = in_bytes, out_bytes return in_traffic, out_trafficnext_thread = Noneexit_flag = Falsedef thread_job(f_handler, inf='eth0', interval=2): global next_thread, exit_flag time.sleep(interval) if not exit_flag: next_thread = threading.Thread(target=thread_job, args=(f_handler, inf, interval)) next_thread.start() else: next_thread = None time_stamp = int(time.time()) in_traffic, out_traffic = curr_traffic(inf) print in_traffic, out_traffic if in_traffic is not None and out_traffic is not None and not f_handler.closed: f_handler.write('%d, %d, %d\n' % (time_stamp, in_traffic, out_traffic))def exit_func(signum, stack): global exit_flag exit_flag = True print("Exiting ...") cnt = 0 while not next_thread and cnt &lt; 3: time.sleep(1) cnt += 1 if cnt &gt;= 3: next_thread.exit()def output_traffics(outfile, inf='eth0', interval=1): with open(outfile, 'w') as f: f.write('time, in_rate(B/s), out_rate(B/s)\n') thread_job(f, inf, interval) while not exit_flag: time.sleep(1)if __name__ == '__main__': signal.signal(signal.SIGINT, exit_func) signal.signal(signal.SIGINT, exit_func) args = &#123; 'outfile': time.strftime("%Y%m%d%H%M%S", time.localtime(time.time())) + '.csv', 'inf': 'eth0', 'interval': 1 &#125; output_traffics(**args)]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[LeetCode]Median of Two Sorted Arrays]]></title>
    <url>%2F2015%2F03%2F19%2FLeetCode-Median-of-Two-Sorted-Arrays%2F</url>
    <content type="text"><![CDATA[There are two sorted arrays A and B of size m and n respectively. Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)). 中位数：有m个数，如果m为基数，那么中位数正好是第(m+1)/2个数；如果m为偶数，中位数应该是中间两个数（第m/2和第m/2+1个）的平均值 第一种方法（默认数列从小到大排序）： 寻找中位数就是搜索处于有序数列中间的那个数，可以转化为搜索第k个数的值 如果数列A的长度大于等于k：首先比较数列A的第k个数x和数列B第一个数y。 如果x小于等于y，那么x同时是所有数的第k个数，返回x； 如果x大于y，很遗憾，x在top k以外，那么数列A的第k个到最后的数都被排除了，这样在新的数列A和数列B中搜索top k，这是一个递归过程。 如果数列A的长度小于k的话：那么就比较数列A的最后一个（第m个）x和数列B的第k-m个y。 如果y大于等于x，那么就相当于A数列的m个数都在top k之内，而y正好是第k个。 如果y小于x，那么y显然在top k内，但不是第k个。那么就可以把B数列中y以及y之前的k-m个数都去掉，然后查找第m个数（因为y以及y之前的数都在top k之内，去掉之后，要找的数由第k个变为第m个），递归搜索 1234567891011121314151617181920212223242526272829class Solution &#123;public: double findMedianSortedArrays(int A[], int m, int B[], int n) &#123; if ((m+n) % 2) return findTopK(A, m, B, n, (m+n)/2+1); else return (findTopK(A, m, B, n, (m+n)/2) + findTopK(A, m, B, n, (m+n)/2+1))/2.0; &#125; double findTopK(int A[], int m, int B[], int n, int k) &#123; if (m == 0) return B[k-1]; if (n == 0) return A[k-1]; if (k &lt;= m) &#123; if (A[k-1] &lt;= B[0]) return A[k-1]; else return findTopK(B, n, A, k-1, k); &#125; else &#123; if (A[m-1] &lt;= B[k-m-1]) return B[k-m-1]; else if ((A[m-1] &gt; B[k-m-1])) &#123; return findTopK(A, m, B+k-m, m+n-k, m); &#125; &#125; &#125;&#125;; 第二种方法： 第一种方法中，最坏情况下的复杂度为O(k)。最坏情况就是top k的数字在数列A、B中各占一半。如果k特别大的话，会比较慢。 第二中方法的思路就是每次从A、B数列中各选一部分，总共k个数；然后比较A、B选取部分的最后一个数。小的数肯定属于top k-1，大的数有可能是第k个，也有可能大于k。 举例说明：假如选A的前u个，选B的前v个，u+v=k。然后比较A[u-1]和B[v-1]的大小。假如A[u-1]&gt;B[v-1]，那么A[u-1]是这k个数最大的，B[0]到B[v-1]肯定属于前k-1个数。但A[u-1]也不一定是第k个，因为B中没选的数可能小于它。 因为可以确定B[0]到B[v-1]这v个数都不可能是第k个，直接排除掉。然后采用递归的方式搜索剩下数字的第k-v个数（原来的第k个数）。 在递归过程中，k的值在不断减小，如果等于1的话，直接返回A、B中的最小值。 最后的问题：u和v的选择。尽量将k按比例分布在A、B上，也就是取A、B长度的一半。 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123;public: double findMedianSortedArrays(int A[], int m, int B[], int n) &#123; if ((m + n) % 2) return findTopK(A, m, B, n, (m + n) / 2 + 1); else return (findTopK(A, m, B, n, (m + n) / 2) + findTopK(A, m, B, n, (m + n) / 2 + 1)) / 2; &#125; double findTopK(int A[], int m, int B[], int n, int k) &#123; if (m == 0) return (double)B[k - 1]; if (n == 0) return (double)A[k - 1]; if (k == 1) return A[0] &lt; B[0] ? A[0] : B[0]; if (m &gt; k) m = k; if (n &gt; k) n = k; int mid_a, mid_b; if (m &lt; n) &#123; mid_a = (m-1)/2; mid_b = k - mid_a - 2; &#125; else &#123; mid_b = (n-1)/2; mid_a = k - mid_b - 2; &#125; if (A[mid_a] &lt; B[mid_b]) return findTopK(A+mid_a+1, m-mid_a-1, B, n, k-mid_a-1); else if (A[mid_a] &gt; B[mid_b]) return findTopK(A, m, B+mid_b+1, n-mid_b-1, k-mid_b-1); else return A[mid_a]; &#125;&#125;;]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[译]管理堆空间：使用JVMTI循环类实例]]></title>
    <url>%2F2015%2F03%2F12%2F%E8%AF%91-%E7%AE%A1%E7%90%86%E5%A0%86%E7%A9%BA%E9%97%B4%EF%BC%9A%E4%BD%BF%E7%94%A8JVMTI%E5%BE%AA%E7%8E%AF%E7%B1%BB%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[好久没更新了，把为伯乐在线、Importnew翻译的一篇文章发上来吧。 原文：http://www.javacodegeeks.com/2014/12/own-your-heap-iterate-class-instances-with-jvmti.html 今天我想探讨Java的另一面，我们平时不会注意到或者不会使用到的一面。更准确的说是关于底层绑定、本地代码（native code）以及如何实现一些小魔法。虽然我们不会在JVM层面上探究这是怎么实现的，但我们会通过这篇文章展示一些奇迹。 我在ZeroTurnaround的RebelLabs团队中主要工作是做研究、撰文、编程。这个公司主要开发面向Java开发者的工具，大部分以Java插件（javaagent）的方式运行。经常会遇到这种情况，如果你想在不重写JVM的前提下增强JVM或者提高它的性能，你就必须深入研究Java插件的神奇世界。插件包括两类：Java javaagents和Native javaagents。本文主要讨论后者。 Anton Arhipov——XRebel产品的领导者，在布拉格的GeeCON会议上做了“Having fun with Javassist”的演讲。这个演讲可以作为了解完全使用Java开发javaagents的一个起点。 本文中，我们会创建一个小的Native JVM插件，探究向Java应用提供Native方法的可能性以及如何使用Java虚拟机工具接口(JVM TI)。 如果你想从本文获取一些干货，那是必须的。剧透下，我们可以计算给定类在堆空间中包含多少实例。 假设你是圣诞老人值得信赖的一个黑客精灵，圣诞老人有一些挑战让你做： Santa： 我亲爱的黑客精灵，你能写一个程序，算出当前JVM堆中有多少Thread实例吗？ 一个不喜欢挑战自己的精灵可能会答道： 很简单，不是么？ 1return Thread.getAllStackTraces().size(); 但是如果把问题改为任意给定类（不限于Thread），如何重新设计我们的方案呢？我们是不是得实现下面这个接口？ 123public interface HeapInsight &#123; int countInstances(Class klass);&#125; 这不可能吧？如果String.class作为输入参数会怎么样呢？不要害怕，我们只需深入到JVM内部一点。对JVM库开发者来说，可以使用JVMTI，一个Java虚拟机工具接口（Java Virtual Machine Tool Interface）。JVMTI添加到Java中已经很多年了，很多有意思的工具都使用JVMTI。JVMTI提供了两类接口： Native API Instrumentation API，用来监控并转换加载到JVM中类的字节码 在我们的例子中，我们要使用Native API。我们想要用的是IterateThroughHeap函数，我们可以提供一个自定义的回调函数，对给定类的每个实例都可以执行回调函数。 首先，我们先创建一个Native插件，可以加载并显示一些东西，以确保我们的架构没问题。 Native插件是用C/C++实现的，并编译为一个动态库，它在我们开始考虑Java前就已经被加载了。如果你对C++不熟，没关系，很多精灵都不熟，而且也不难。我写C++时主要有两个策略：靠巧合编程、避免段错误。所以，当我准备写下本文的代码和说明时，我们都可以练一遍。 下面就是创建的第一个native插件： 12345678910#include #include using namespace std; JNIEXPORT jint JNICALL Agent_OnLoad(JavaVM *jvm, char *options, void *reserved)&#123; cout &lt;&lt; "A message from my SuperAgent!" &lt;&lt; endl; return JNI_OK;&#125; 最重要的部分就是我们根据动态链接插件的文档声明了一个Agent_OnLoad的函数， 保存文件为“native-agent.cpp”，接下来让我们把它编译为动态库。 我用的是OSX，所以我可以使用clang编译。为了节省你google搜索的功夫，下面是完整的命令： 1clang -shared -undefined dynamic_lookup -o agent.so -I /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/include/ -I /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/include/darwin native-agent.cpp 这会生成一个agent.so文件，就是供我们使用的动态库。为了测试它，我们创建一个hello world类。 123456package org.shelajev;public class Main &#123; public static void main(String[] args) &#123; System.out.println("Hello World!"); &#125;&#125; 当你运行时，使用-agentpath选项正确地指向agent.so文件，你应该可以看到以下输出： 123java -agentpath:agent.so org.shelajev.MainA message from my SuperAgent!Hello World! 做的不错！现在，我们准备让这个插件真正地起作用。首先，我们需要一个jvmtiEnv实例。它可以在Agent_OnLoad执行时通过JavaVM *jvm获得，但之后就不行了。所以我们必须把它保存在一个可全局访问的地方。我们声明了一个全局结构体来保存它。 1234567891011121314151617181920212223242526272829303132#include #include using namespace std; typedef struct &#123; jvmtiEnv *jvmti;&#125; GlobalAgentData; static GlobalAgentData *gdata; JNIEXPORT jint JNICALL Agent_OnLoad(JavaVM *jvm, char *options, void *reserved)&#123; jvmtiEnv *jvmti = NULL; jvmtiCapabilities capa; jvmtiError error; // put a jvmtiEnv instance at jvmti. jint result = jvm-&gt;GetEnv((void **) &amp;jvmti, JVMTI_VERSION_1_1); if (result != JNI_OK) &#123; printf("ERROR: Unable to access JVMTI!\n"); &#125; // add a capability to tag objects (void)memset(capa, 0, sizeof(jvmtiCapabilities)); capa.can_tag_objects = 1; error = (jvmti)-&gt;AddCapabilities(capa); // store jvmti in a global data gdata = (GlobalAgentData*) malloc(sizeof(GlobalAgentData)); gdata-&gt;jvmti = jvmti; return JNI_OK;&#125; 我们也更新了部分代码，让jvmti实例可以使用对象tag（tag：对象附带一个值，参见JVMTI文档），因为遍历堆的时候需要这么做。准备都已就绪，我们拥有了已初始化的JVMTI实例。我们通过JNI将它提供给Java代码使用。 JNI表示Java Native Interface，是在Java应用中调用native代码的标准方式。Java部分相当简单直接，在Main类中添加countInstances方法的定义，如下所示： 1234567891011package org.shelajev;public class Main &#123; public static void main(String[] args) &#123; System.out.println("Hello World!"); int a = countInstances(Thread.class); System.out.println("There are " + a + " instances of " + Thread.class); &#125; private static native int countInstances(Class klass);&#125; 为了适应native方法，我们必须修改我们的native插件代码。我稍后会解释，现在在其中添加下面的函数定义： 123456789101112131415161718extern "C"JNICALL jint objectCountingCallback(jlong class_tag, jlong size, jlong* tag_ptr, jint length, void* user_data) &#123; int* count = (int*) user_data; *count += 1; return JVMTI_VISIT_OBJECTS;&#125; extern "C"JNIEXPORT jint JNICALL Java_org_shelajev_Main_countInstances(JNIEnv *env, jclass thisClass, jclass klass) &#123; int count = 0; jvmtiHeapCallbacks callbacks;(void)memset(&amp;callbacks, 0, sizeof(callbacks));callbacks.heap_iteration_callback = &amp;objectCountingCallback; jvmtiError error = gdata-&gt;jvmti-&gt;IterateThroughHeap(0, klass, &amp;callbacks, &amp;count); return count;&#125; 这里的Java_org_shelajev_Main_countInstances 方法更有趣，它以Java_开始，接着以_分隔的完整类名称，最后是Java中的方法名。同样不要忘记了JNIEXPORT声明，表示这个方法将要导入到Java世界中。 在Java_org_shelajev_Main_countInstances函数内部，首先我们声明了objectCountingCallback函数作为回调函数，然后调用IterateThroughHeap函数，它的参数通过Java程序传入。 注意，我们的native方法是静态的，所以C语言对应的参数是： 1JNIEnv *env, jclass thisClass, jclass klass 如果是实例方法的话，参数会有点不一样： 1JNIEnv *env, jobj thisInstance, jclass klass 其中thisInstance指向调用Java方法的实例。 现在直接根据文档给出objectCountingCallback的定义，主要内容不过是递增一个int变量。 Boom！搞定了！感谢你的耐心。如果你仍在阅读，可以尝试运行下上述代码。 重新编译native插件，并运行Main class。我的结果如下： 123java -agentpath:agent.so org.shelajev.MainHello World!There are 7 instances of class java.lang.Thread 如果我在main方法中添加一行Thread t = new Thread();，结果就是8个。看上去插件确实起作用了。你的数目肯定会和我不一样，没事，这很正常，因为它要算上统计、编译、GC等线程。 如果我想知道堆内存中String的数量，只需改变class参数。这是一个真正泛型的解决方案，我想圣诞老人会高兴的。 你对结果感兴趣的话，我告诉你，结果是2423个String实例。对这么个小程序来说，数量相当大了。 如果执行：1return Thread.getAllStackTraces().size(); 结果是5，不是8。因为它没有算上统计线程。还要考虑这种简单的解决方案么？ 现在，通过本文和相关知识的学习，我不敢说你可以开始写自己的JVM监控或增强工具，但这肯定是一个起点。 在本文中，我们从零开始写了一个Java native插件，编译、加载、并成功运行。这个插件使用JVMTI来深入JVM内部（否则无法做到）。对应的Java代码调用native库并生成结果。 这是很多优秀的JVM工具经常采用的策略，我希望我已经为你解释清楚了其中的一些技巧。]]></content>
      <tags>
        <tag>java</tag>
        <tag>翻译</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[社区划分-Laplace矩阵与谱划分算法]]></title>
    <url>%2F2015%2F01%2F23%2F%E7%A4%BE%E5%8C%BA%E5%88%92%E5%88%86-Laplace%E7%9F%A9%E9%98%B5%E4%B8%8E%E8%B0%B1%E5%88%92%E5%88%86%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[社区划分实际的网络可能有若干个社区组成，社区内部的节点之间连接紧密，但社区之间的连接却比较稀疏。如下图所示，相同颜色的节点连接紧密，不同颜色的节点连接稀疏。同一种颜色的节点可以划分到同一个分区中。 Laplace矩阵###定义对于一个简单图$G$，它可以用Laplace矩阵$L=(l_{ij})_{n\times n}$来表示（$n$为$G$中节点数）。它的定义如下： $l_{ij}=\left\{ \begin{array}{ll} deg(v_i) & \textrm{if $i=j$}\\ -1 & \textrm{if $v_i$ connect to $v_j$}\\ 0 & \textrm{otherwise} \end{array}\right.$ 也就是说，$L$是一个$n\times n$的矩阵，$n$为图$G$的节点数。对角线上的元素$l_{ii}$的值为节点$v_i$的度。其他位置的元素，如果节点$v_i$与节点$v_j$相连（$i\neq j$），则值为$-1$，否则值为$0$。 那么矩阵$L$可以表示为：$L=D-A$。矩阵$D$是图$G$的度矩阵，对角线上的元素表示各节点的度，其他元素为$0$。矩阵$A$表示图$G$的邻接矩阵。 性质 $L$为实对称矩阵 对$L$的每行或者每列求和都等于0 矩阵$L$有一个特征值为0，对应的特征向量为${1,1,\dots ,1}$。（因为$L\cdot\{1,1,\dots ,1\}=0$） 矩阵$L$的其他特征值均大于$0$。 谱划分算法谱划分算法是利用图的Laplace矩阵的特征值和特征向量对图实现划分的一种算法。从线性空间的角度来理解，矩阵的特征向量可以理解为线性空间中相互正交的“基”（三维空间的三个维度），对应的特征值表示矩阵在各个基上的投影长度，特征值和特征向量唯一地确定了矩阵在线性空间中的位置。 划分思想假设图$G$由完全独立的两个社区组成，也就是说图$G$由两部分组成。那么它的Laplace矩阵经过行列的交换，可以写成一个分块对角阵。主对角线上的两个对角块矩阵正好分别是两个社区自身的Laplace矩阵。 以上图的图$G$为例，它包含两个独立的社区。其Laplace矩阵为： $L=\left( \begin{array}{cccccc|ccccc} 2 & -1 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ -1 & 5 & -1 & -1 & -1 & -1 & 0 & 0 & 0 & 0 & 0 \\ -1 &-1 & 5 &-1 &-1 &-1 & 0 & 0 & 0 & 0 & 0 \\ 0 & -1 &-1 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 0 &-1 &-1 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 0\\ 0 &-1 &-1 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 0\\ \hline 0 & 0 & 0 & 0 & 0 & 0 & 4 &-1 &-1 &-1 &-1\\ 0 & 0 & 0 & 0 & 0 & 0 &-1 & 2 & 0 & 0 &-1\\ 0 & 0 & 0 & 0 & 0 & 0 &-1 & 0 & 1 & 0 & 0\\ 0 & 0 & 0 & 0 & 0 & 0 &-1 & 0 & 0 & 2 &-1\\ 0 & 0 & 0 & 0 & 0 & 0 &-1 &-1 & 0 &-1 & 3\\ \end{array} \right)$ 求解矩阵的特征值和特征向量。如下式所示，特征值用$E$表示，特征向量矩阵用$V$表示： $\left( \begin{array}{c} E\\ \hline V\\ \end{array} \right)=\left( \begin{array}{cccccc|ccccc} -0. & 2. & 6. & 6. & 2. & 2. & 5. & 0. & 4. & 2. & 1.\\ \hline -0.408 & -0.866 & -0.289 & -0.144 & -0. & -0. & 0. & 0. & 0. & 0. & 0.\\ -0.408 & -0. & 0.577 & 0.901 & 0. & 0. & 0. & 0. & 0. & 0. & 0.\\ -0.408 & -0. & 0.577 & -0.324 & -0. & -0. & 0. & 0. & 0. & 0. & 0.\\ -0.408 & 0.289 &-0.289 &-0.144 &-0. & -0.73 & 0. & 0. & 0. & 0. & 0.\\ -0.408 & 0.289 &-0.289 &-0.144 &-0.707 & 0.049 & 0. & 0. & 0. & 0. & 0.\\ -0.408 & 0.289 & -0.289 & -0.144 & 0.707 & 0.681 & 0. & 0. & 0. & 0. & 0.\\ 0. & 0. & 0. & 0. & 0. & 0. & 0.894 & -0.447 & -0. & 0. & 0.\\ 0. & 0. & 0. & 0. & 0. & 0. &-0.224 &-0.447 &-0.408 & 0.707 &-0.289\\ 0. & 0. & 0. & 0. & 0. & 0. & -0.224 &-0.447 &-0. &-0. & 0.866\\ 0. & 0. & 0. & 0. & 0. & 0. & -0.224 &-0.447 &-0.408 &-0.707 &-0.289\\ 0. & 0. & 0. & 0. & 0. & 0. & -0.224 &-0.447 & 0.816 & 0. & -0.289\\ \end{array} \right)$ 特征向量矩阵也是分块的形式，子块分别对应于每个社区的特征向量矩阵。此时，特征值0对应的特征向量有两个，分别对应于两个社区。所以Laplace矩阵中，特征值0对应的特征向量的个数，表示图$G$非联通分区的个数，对应于我们例子中的两个独立的社区。]]></content>
      <tags>
        <tag>算法</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ServiceLoader的使用]]></title>
    <url>%2F2015%2F01%2F14%2FServiceLoader%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[ServiceLoader是Java SE 6所提供的API，用于自动实例化继承了给定接口（或抽象类）的类，类似于Spring依赖注入的功能。 根据其官方文档，对于ServiceLoader来说，有两个概念需要弄清楚： service：指已定义好的接口或者抽象类 service provider：指实现了特定service的具体类 ServiceLoader是一个泛型类，它的类型参数就表示service，需要实例化类型的超类（接口或抽象类）。 那么，需要实例化哪些provider呢，也就是继承了service的具体类？这需要在resource路径下的META-INF/services目录中定义一个配置文件。这个配置文件的名称必须用service的绝对包路径来命名。文件的内容就是需要被实例化的provider：一行一个，必须是provider的绝对包路径。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Floodlight源码分析（1）]]></title>
    <url>%2F2015%2F01%2F13%2FFloodlight%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[基本概念在详细分析模块加载过程之前，先了解几个核心概念。 1.模块(Module)Module是指继承了IFloodlightModule接口的类。IFloodlightModule定义如下： 1234567891011121314public interface IFloodlightModule &#123; //获取module包含的service public Collection&lt;Class&lt;? extends IFloodlightService&gt;&gt; getModuleServices(); public Map&lt;Class&lt;? extends IFloodlightService&gt;, IFloodlightService&gt; getServiceImpls(); //获取module依赖service public Collection&lt;Class&lt;? extends IFloodlightService&gt;&gt; getModuleDependencies(); void init(FloodlightModuleContext context) throws FloodlightModuleException; void startUp(FloodlightModuleContext context) throws FloodlightModuleException; &#125; 我们知道，在Java中，一个类，可以有多个实例。但在Floodlight系统中，每个Module类只包含一个module实例。Module类通过ServiceLoader只实例化一个module实例，类似于Spring框架的功能，详见3.2.2节。 （约定：以下内容中，首字母大写的Module表示类，小写的module表示实例） 2.服务(Service)Service是指继承了IFloodlightService接口的类。IFloodlightService定义如下，是一个空接口，保证类型安全： 123public abstract interface IFloodlightService &#123; // This space is intentionally left blank....don&apos;t touch it&#125; 3.配置需要启动的ModuleFloodlight从命令行启动的时候，可以加上配置文件参数（见第2节）；如果没有添加，则启动默认的配置文件。 可以在这个配置文件中定义一个Module列表，这些Module在Floodlight运行的时候自动启动。 4.Module与Service的关系 一个Module可以包含多个Service。 一个Service也可以被多个Module包含。 但是，对于定义在配置文件（见3.2.1）中将要启动的Module，任意两个Module不能包含相同的Service。 总结一下：Module和Service可以是Many-to-Many的关系；但是对于定义在配置文件中的所有Module，是one-to-Many的关系。 5.依赖关系一个Module可能依赖于多个Service，通过调用getModuleDependencies方法获取module实例所依赖的Service。 定义在配置文件的Module在启动前，程序会解决依赖问题。如果一个Module依赖一个Service，那么程序会加载包含这个Service的Module解决依赖。如果包含这个Service的Module有多个，那么必须选一个，显式写在配置文件中。 Main函数main函数很简单（除去注释、空行，只有十几行），也很容易理解，主要包括以下几部分内容： 解析命令行参数 加载自定义模块 启动REST服务器 启动Controller 这几部分在接下来的几节中详细论述。 命令行参数解析程序使用CmdLineParser解析命令参数。CmdLineSetting定义了命令行参数的格式：-cf[--configFile] FILE，用来通过命令行传入配置文件路径。 12@Option(name=&quot;-cf&quot;, aliases=&quot;--configFile&quot;, metaVar=&quot;FILE&quot;, usage=&quot;Floodlight configuration file&quot;)private String configFile = DEFAULT_CONFIG_FILE; 默认情况下，配置文件路径为“config/floodlight.properties”。 FloodlightModuleLoader从主函数可以看到，它实例化了FloodlightModuleLoader，用来加载模块，而这个类也继承了IFloodlightService接口，所以它可以看作是一种特殊的Service，用来加载Module的Service。 在详细说明FloodlightModuleLoader功能之前，我先介绍一下它内部的几个静态成员变量： serviceMap：Service类型与所属的多个modules实例的映射关系 moduleService：module实例与包含的Services类型的映射关系 moduleNameMap：Module名称与module实例的映射关系 FloodlightModuleLoader主要做了三件事（loadModulesFromConfig方法）： 解析配置文件，读取其中的Module名称（用于第三步启动） 利用ServiceLoader实例化所有Module 对于2中的所有实例，只启动配置文件所定义的类型 1.解析配置文件参见loadModulesFromConfig方法。配置文件是Properties文件，以等号（“=”）分隔属性名和属性值，使用java.util.Properties就可以解析。 “floodlight.modules”属性对应的值是以逗号分隔的Module类名字符串。这表示要启动的多个模块。 “floodlight.confd”属性对应的值是子配置文件目录。这个目录可以包含多个子配置文件，每个文件中也可以包含“floodlight.modules”属性，对应的以逗号分隔Module名也需要被启动。 第1步：将“floodlight.modules”属性定义的多个Module类名，存放到列表中第2步：如果有“floodlight.confd”属性，解析对应的子配置文件目录，递归解析所有的子配置文件第3步：返回结果列表 2.实例化所有Module这部分的内容主要包含在findAllModules方法中。 ServiceLoader是Java SE 6所提供的API，用于自动实例化继承了给定接口（或抽象类）的类，类似于Spring依赖注入的功能。ServiceLoader的使用请参见《ServiceLoader的使用》 ServiceLoader为resource/META-INF/services/net.floodlightcontroller.core.module.IFloodlightModule文件中定义的所有类都创建了一个实例。这些类全部实现了IFloodlightModule，所以可以这么说，ServiceLoader为这个文件中所有的Module创建了一个实例。 然后更新serviceMap、moduleService和moduleNameMap这三个静态变量。 最后，检查配置文件中包含的Module类，是否存在两个以上的Module包含相同的service，否则抛出异常。 3.启动配置文件定义的Module这部分内容主要在loadModulesFromList方法中。主要过程为： 将需启动的Module实例加入到启动列表中 将依赖的Module实例加入启动列表中（递归添加依赖Module） 启动上述列表中的所有实例 从“解析配置文件”小节中已知道，解析配置文件后，返回一个列表（Collection&lt;String&gt;），其中包含要启动的Module名称。接下来，循环迭代这个列表，根据Module名称从moduleNameMap中获取对应的module实例。然后把这个实例添加到启动列表中。 如果这个module实例依赖于其他一个或多个Service，那么需要解决依赖，将包含这些Service的module实例也添加到启动列表。]]></content>
      <tags>
        <tag>java</tag>
        <tag>sdn</tag>
        <tag>floodlight</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Java反射解析JSON配置文件]]></title>
    <url>%2F2015%2F01%2F06%2F%E4%BD%BF%E7%94%A8Java%E5%8F%8D%E5%B0%84%E8%A7%A3%E6%9E%90JSON%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[什么是JSONJSON(JavaScript Object Notation)是指Javascript对象表示法。JSON是Javascript的一个子集，但JSON是一种独立的文本格式，用来存储和交换文本信息的语法。类似 XML。详细介绍可以参见介绍JSON。 对于动态语言比如Javascript、Python来说，解析JSON属于小菜一碟；但对于静态强类型语言来说，解析JSON要费点功夫。尽管Java解析JSON比较麻烦，幸运的是，Java已经有很多强大的JSON解析器。 解析工具本文使用org.json来解析JSON数据。org.json是非常轻量级的JSON解析器，不依赖于其他库。 JSON有两种数据类型：对象和数组。 对象：通过花括号包含的键/值对 数组：通过方括号包含的有序列表 这两种类型分别对应于org.json的JSONObject和JSONArray。 解析思路需求：将配置文件中的JSON字符串转换为某个实例（比如自定义的Config类或Map）。 分析： 生成的“某个实例”到底是哪一个呢？可以增加一个输入参数Class&lt;?&gt;，表示生成实例的类型。 如果指定的类型不是Map，那么这个类型必须要包含JSON所有键所对应的域。比如JSON对象为{&quot;name&quot; : &quot;Tim&quot;, &quot;age&quot; : 20}，那么指定的类型必须包含String类型的name域和数值类型的age域。 输入：1. JSON字符串或者代表JSON字符串的JSONObject；2. Class&lt;?&gt;表示生成实例的类型 输出：对应的实例 第1步如果定义一个函数json2obj来操作，函数的返回类型与Class&lt;?&gt;输入参数有关，不是固定的，所以可以采用泛型。那么json2obj的框架可以这么写： 123public &lt;T&gt; T json2obj(JSONObject json, Class&lt;T&gt; Cls) &#123; ...&#125; 第2步现在可以想一个大致的步骤了：如果指定的类型是Map或其子类，那么就将JSON转化为Map实例（JSON的键/值对可以对应于Map的键/值对）；否则，根据Class参数生成对应实例，将JSON中的键/值对填入到该实例对应的域中，这显然得用到反射。 1234567891011121314public &lt;T&gt; T json2obj(JSONObject json, Class&lt;T&gt; Cls) &#123; if (Map.class.isAssignableFrom(Cls)) &#123; T map = 解析json到map; return map; &#125; T res = Cls.newInstance(); Iterator&lt;String&gt; iter = json.keys(); while (iter.hasNext()) &#123; key = iter.next(); value = json.get(key); 设置res对应于key的域 &#125; return res&#125; 第3步先将JSON转化为Map实例，这个比较容易：定义一个新的函数json2map，将JSON的键值对逐个填入到map实例中，并修改原来的json2obj函数。 12345678910111213141516171819202122232425private Map&lt;String, Object&gt; json2map(JSONObject json, Class&lt;Map&lt;String, Object&gt;&gt; mapCls) &#123; Map&lt;String, Object&gt; map = mapCls.newInstance(); Iterator&lt;String&gt; iter = json.keys(); String key; while (iter.hasNext()) &#123; key = iter.next(); map.put(key, json.get(key)); &#125; return map;&#125;public &lt;T&gt; T json2obj(JSONObject json, Class&lt;T&gt; Cls) &#123; if (Map.class.isAssignableFrom(Cls)) &#123; return (T)json2map(json, (Class&lt;Map&lt;String, Object&gt;&gt;) Cls); &#125; T res = Cls.newInstance(); Iterator&lt;String&gt; iter = json.keys(); while (iter.hasNext()) &#123; key = iter.next(); value = json.get(key); 设置res对应于key的域 &#125; return res&#125; 第4步现在考虑普通实例的转换。如果key对应的value是普通类型，即字符串或数值，那么直接把值填写到对应的域中即可；如果value是对象（JSONObject），那么把value转化为对应域类型的实例，递归地调用json2obj函数。 接下来设置key对应的域：如果这个域是public的，直接设置；否则通过对应的setter方法设置。 123456789101112131415161718 ...while (iter.hasNext()) &#123;key = iter.next();value = json.get(key); Field field = Cls.getDeclaredField(key);// recursionif (value instanceof JSONObject) value = json2obj((JSONObject) value, field.getType()); if (Modifier.isPublic(field.getModifiers())) &#123; field.setAccessible(true); field.set(res, value);&#125; else &#123; // not accessible, use setter method String methodName = &quot;set&quot; + Character.toUpperCase(key.charAt(0)) + key.substring(1); Method setMethod = Cls.getMethod(methodName, field.getType()); setMethod.invoke(res, value);&#125; &#125; ... 总结本文主要通过反射将JSON转化为Java实例，实例类型由输入参数Class&lt;T&gt; Cls决定，可以是Map类或者普通类。如果Java类是普通类，必须包含JSON对象所有键（key）所对应的同名同类型域，且可设置（public或者setter方法）。比如JSON包含名为”name”的key，那么Java类也应该包含name的域。JSON对象内也可以包含JSON对象，Java类内部也必须包含其他Java类型的域。程序通过递归的方式解析。 本文没有考虑JSON数组的转化。]]></content>
      <tags>
        <tag>java</tag>
        <tag>反射</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[社区划分-Newman快速算法]]></title>
    <url>%2F2014%2F12%2F27%2F%E7%A4%BE%E5%8C%BA%E5%88%92%E5%88%86-Newman%E5%BF%AB%E9%80%9F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[回顾在上一篇文章中，我们了解了模块度的定义与计算方法。因为Newman快速算法是通过最优化Modularity的值来实现社区划分的，所以先回顾下Modularity的计算方法。我们最后得到的Modularity计算公式为： $$Q=\sum_i^c(e_{ii}-a_{i}^2)$$ 其中： c表示社区数 $e_{ij}+e_{ji}$表示连接社区i和社区j边的概率，$e_{ij}=e_{ji}$分别为概率的一半。 $e_{ii}$表示在社区i内边的概率。 $a_i=\sum_j{e_{ij}}$表示在端点在社区i中的概率。 如果端点之间随机连接，也就是在随机情况下，社区i内部边的概率为$a_{ii}^2$。 Modularity用来评价社区划分结果的好坏，Q值越大，划分结果越好。如果一个图是随机的，那么它的模块度应该为0。 思想既然Modularity可以用来评价社区划分结果的好坏，那么是不是可以设计一个算法，直接以Modularity为优化目标，实现社区划分。 这一优化问题的解空间有多大呢？简单计算下，假设有n个节点。 如果划分为一个社区，那个只有1个解：所有节点都属于这个社区； 如果划分为两个社区，那么每个节点有两种选择：要么属于第一个社区，要么属于第二个社区，总共$2^n$种选择。但划分的结果，即两个社区，是没有顺序的，需要除以2，还得减去把所有节点都分到一个社区的情况，即$2^{n-1}-1$种解。 仅仅这两种情况，解空间就随n呈指数增长，这个问题显然是NP-hard问题。 Newman快速算法是凝聚式的贪心算法。所谓凝聚，就是算法先将各个节点初始化为单个分区，然后逐步将关联度高的分区合并到一起，最后形成大的划分方案。在合并的过程中，每一步选择两个分区合并，使得合并后使Q增长最大（或者减小最小）。 社区i和社区j合并前： $$\begin{aligned} Q_{before} &=\sum_{k\neq i,j}^c(e_{kk}-a_{k}^2)+(e_{ii}-a_{i}^2)+(e_{jj}-a_{j}^2)\\ &=Q'+(e_{ii}-a_{i}^2)+(e_{jj}-a_{j}^2) \end{aligned}$$ 合并后，假设合并后为社区z： $$Q_{after}=Q'+(e_{zz}-a_{z}^2)$$ 其中： $e_{zz}=e_{ii}+e_{jj}+e_{ij}+e_{ji}$，原来在连接社区i和社区j的边现在也属于社区z内部了。 $a_{z}=a_i+a_j$ 那么合并后，Modularity的增量$\Delta Q$： $$\begin{split} \Delta Q &=Q_{after}-Q_{before}\\ &=e_{ij}+e_{ji}-2a_i a_j\\ &=2(e_{ij}-a_i a_j) \end{split}$$ 根据$\Delta Q$的计算方式，我们只需要维护一个$e_{ij}$矩阵就可以计算出合并任意两个社区后的Modularity变化量，而不用计算Q。选择使Modularity增量最大的两个社区进行合并。合并社区i和社区j后，需要更新矩阵，只需要社区i和社区j对应的行相加、对应的列相加即可。 例子将该算法应用在著名的Zachary空手道俱乐部关系网络中。该俱乐部后来产生分歧，分裂为两个小俱乐部。 当Q值达到最大时，为Q=0.381，网络被划分为三个社区，如下图所示： 当网络被划分为两个社区时，Q=0.372。与实际情况对比，只有节点10未被划分正确。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960def newman_partition(graph, n_groups=1, min_delta_q=0, weight=None): """ partition a graph according its structure :param graph: undirected networkx graph :param n_groups: number of groups would be partitioned :param min_delta_q: stop condition: if the increased 'q' (modularity) by joining two partitions was less than min_delta_q :param weight: key value for edge dict :return: a list of sets each of which contains the nodes belong to the same partition """ m = graph.number_of_edges() p_id = 1 groups, a = &#123;&#125;, &#123;&#125; q, total_weight = 0, 0 for edge in graph.edges(): total_weight += graph[edge[0]][edge[1]].get(weight, 1) for node in graph.nodes(): groups[p_id] = (node, ) a[p_id] = graph.degree(node, weight)/2/total_weight q -= a[p_id]**2 p_id += 1 e = defaultdict(dict) for i in range(1,len(groups)+1): for j in range(i, len(groups)+1): if groups[j][0] in graph[groups[i][0]]: e[i][j] = graph[groups[i][0]][groups[j][0]].get(weight, 1)/2/total_weight e[j][i] = e[i][j] while True: delta_q = -9999999 merge = None for (i, j) in combinations(groups.keys(), 2): if j in e[i] and i in e[j]: tmp = e[i][j] + e[j][i] - 2 * a[i]*a[j] delta_q, merge = (tmp, (i, j)) if tmp &gt; delta_q else (delta_q, merge) #join i, j = merge adjs = set(e[i].keys() + e[j].keys()) adjs.remove(i) adjs.remove(j) for k in adjs: e[p_id][k] = e[i].get(k, 0) + e[j].get(k, 0) e[k][p_id] = e[k].get(i, 0) + e[k].get(j, 0) if i in e[k]: del e[k][i] if j in e[k]: del e[k][j] del e[i], e[j] a[p_id] = a[i] + a[j] groups[p_id] = groups[i] + groups[j] del groups[i], groups[j] del a[i], a[j] p_id += 1 q += delta_q if delta_q &lt; min_delta_q or len(groups) &lt;= n_groups: break return (set(value) for value in groups.values())]]></content>
      <tags>
        <tag>算法</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[社区划分评价指标-Modularity]]></title>
    <url>%2F2014%2F12%2F10%2FModularity%2F</url>
    <content type="text"><![CDATA[作用随着人们对网络的深入研究，在现实中的很多场景中，网络会具有一定的社区结构，比如社交网络、计算机网络。根据网络的结构，网络可以划分为不同的社区，社区内的节点连接紧密，社区之间的节点连接稀疏。比如下图的网络结构。 很多研究人员提出了各种社区划分算法，比如基于特征值的谱划分法、基于介数或中心度的凝聚或分裂类算法。对于相同的数据，不同的算法可能会得到不同的结果。那么如何评价某一算法的划分结果的好坏呢？模块度（Modularity）就是用来评价一个划分结果的量。 定义模块度是指落在社区内链路的比例减去链路是随机分布的情形下落在社区内比例。感觉很拗口，下面详细说明。 首先定义几个符号： 图$G(V,E)$包含n个顶点、m条链路，即$|V|=n,|E|=m$ 用$\delta_{vw}$表示节点v、w是否在同一社区中：等于1，表示v、w在同一社区中；等于0，表示v、w在不同社区中。 矩阵$A$表示图G的邻接矩阵，$A_{vw}=0$表示节点v、w之间没有链路，$A_{vw}=1$表示v、w之间存在链路。 $k_v$表示节点v的度 计算社区内链路数目可以很容易地写出，社区内链路数目为： $$1/2\sum_{vw}A_{vw}\cdot \delta_{vw}$$ 链路随机分布的情况保持原来节点的度不变的情况下（每个节点连接的链路总数不变），但所有链路随机连接到其他节点。 再详细一点： 将原图$G$中的每条链路从中间断开，形成两个stub（那么节点v拥有$k_v$个stub，$k_v$为节点v的度）。 现在整个图有$2m$个stub。 让stub之间随机连接（单个节点上可能出现环），每个stub只能连接一条链路 这样生成新的图$G’$，其中每个节点的度与原图是一样的。 那么链路随机分布的情况下，节点v、w之间的链路期望数目为：$\frac{k_v k_w}{2m}$ 随机情况下，社区内链路期望数目为： $$1/2\sum_{vw}\frac{k_v k_w}{2m}$$ 将两种情况的社区内链路数目相减，并除以总链路数就得到了Modularity： $$Q=\frac{1}{2m}\sum_{vw}(A_{vw}-\frac{k_v k_w}{2m})\delta_{vw}$$ 另一种定义假设整个图G可以被划为c个社区，定义$e_{ij}$表示链路连接社区i和社区j的概率，那么在社区内的链路概率为： $$\sum_{vw}{\frac{A_{vw}\delta_{vw}}{2m}}=\sum_i^c{e_{ii}}$$ 定义$a_i=\sum_j{e_{ij}}$表示链路的任一节点落在社区i的概率。那么在随机情况下，社区i和社区j之间存在的链路概率为$a_i a_j$。${a_i}^2$表示在随机情形下，链路落在社区i中的概率。 这样模块度可以表示为： $$Q=\sum_i^c(e_{ii}-a_{ii}^2)$$]]></content>
      <tags>
        <tag>算法</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单纯形法]]></title>
    <url>%2F2014%2F12%2F06%2F%E5%8D%95%E7%BA%AF%E5%BD%A2%E6%B3%95%2F</url>
    <content type="text"><![CDATA[作用单纯形法是解决线性规划问题的一个有效的算法。线性规划就是在一组线性约束条件下，求解目标函数最优解的问题。 线性规划的一般形式在约束条件下，寻找目标函数z的最大值。 $$\begin{array}{l} \max z={x_1}+{x_2}\\ s.t.\left\{ \begin{array}{*{20}{c}} 2{x_1}+{x_2}\le 12\\ {x_1}+2{x_2}\le 9\\ {x_1},{x_2}\ge 0 \end{array}\right. \end{array}$$ 线性规划的可行域满足线性规划问题约束条件的所有点组成的集合就是线性规划的可行域。若可行域有界（以下主要考虑有界可行域），线性规划问题的目标函数最优解必然在可行域的顶点上达到最优。 单纯形法就是通过设置不同的基向量，经过矩阵的线性变换，求得基可行解（可行域顶点），并判断该解是否最优，否则继续设置另一组基向量，重复执行以上步骤，直到找到最优解。所以，单纯形法的求解过程是一个循环迭代的过程。 线性规划的标准形式在说明单纯形法的原理之前，需要明白线性规划的标准形式。因为单纯形算法是通过线性规划的标准形来求解的。一般，规定线性规划的标准形式为： $$\begin{array}{l} \max z = \sum\limits_{j = 1}^n {{c_j}{x_j}} \\ s.t.\left\{ {\begin{array}{*{20}{c}} {\sum\limits_{j = 1}^n {{a_{ij}}{x_j} = {b_j}, i = 1,2,...,m} }\\ {x_j \ge 0, j = 1,2,...,n} \end{array}} \right. \end{array}$$ 写成矩阵形式： $$\begin{array}{l} \max z = CX\\ AX = b\\ X \ge 0\\ A = \left[ {\begin{array}{*{20}{c}} {{a_{11}}}&{{a_{12}}}& \cdots &{{a_{1n}}}\\ \vdots & \vdots & \ddots & \vdots \\ {{a_{m1}}}&{{a_{m2}}}& \cdots &{{a_{mn}}} \end{array}} \right] \end{array}$$ 标准形的形式为： 目标函数要求max 约束条件均为等式 决策变量为非负约束 普通线性规划化为标准形： 1）若目标函数为最小化，可以通过取负，求最大化2）约束不等式为小于等于不等式，可以在左端加入非负松弛变量，转变为等式，比如： $${x_1}+2{x_2} \le 9 \Rightarrow \left\{ {\begin{array}{*{20}{c}} {{x_1}+2{x_2}+{x_3} = 9}\\ {{x_3} \ge 0} \end{array}} \right.$$ 同理，约束不等式为大于等于不等式时，可以在左端减去一个非负松弛变量，变为等式。 3）若存在取值无约束的变量，可转变为两个非负变量的差，比如： $$- \infty \le {x_k} \le + \infty \Rightarrow \left\{ {\begin{array}{*{20}{c}} {{x_k} = {x_m} - {x_n}}\\ {{x_m},{x_n} \ge 0} \end{array}} \right.$$ 本文最开始的线性规划问题转化为标准形为： $$\begin{array}{l} \max z = {x_1} + {x_2}\\ s.t.\left\{ {\begin{array}{*{20}{c}} {2{x_1}+{x_2}+{x_3} = 12}\\ {{x_1}+2{x_2}+{x_4} = 9}\\ {{x_1},{x_2},{x_3},{x_4} \ge 0} \end{array}} \right. \end{array}$$ 单纯形法几何意义在标准形中，有m个约束条件（不包括非负约束），n个决策变量，且（n&gt;=m）。首先，选取m个基变量$x_j’(j = 1,2,…,m)$ ，基变量对应约束系数矩阵的列向量线性无关。通过矩阵的线性变换，基变量可由非基变量表示： $$x_i'=C_i+\sum_{j=m+1}^{n}m_{ij}x_j'(i=1,2,...,m)$$ 如果令非基变量等于0，可求得基变量的值 ： $$x_i'=C_i$$ 如果为可行解的话，Ci大于0。那么它的几何意义是什么呢？还是通过上述具体的线性规划问题来说明。 $$\begin{array}{l} \max z = {x_1} {x_2}\\ s.t.\left\{ {\begin{array}{*{20}{c}} {2{x_1} {x_2} {x_3} = 12}\\ {{x_1} 2{x_2} {x_4} = 9}\\ {{x_1},{x_2},{x_3},{x_4} \ge 0} \end{array}} \right. \end{array}$$ 如果选择x2、x3为基变量，那么令x1、x4等于0，可以去求解基变量x2、x3的值。对系数矩阵做行变换，如下所示，x2=9/2，x3=15/2 $\left[\begin{array}{*{20}{c}} \rm{X} & {x_1} & {x_2} & {x_3} & {x_4} & b\\ {} & 2 & 1 & 1 & 0 & {12}\\ {} & 1 & 2 & 0 & 1 & 9\\ \rm{C} & 1 & 1 & 0 & 0 & z \end{array} \right] \to \left[\begin{array}{*{20}{c}} \rm{X} & {x_1} & {x_2} & {x_3} & {x_4} & b\\ {} & \textstyle{3 \over 2} & 0 & 1 & -\textstyle{1 \over 2} & \textstyle{{15} \over 2}\\ {} & \textstyle{1 \over 2} & 1 & 0 & \textstyle{1 \over 2} & \textstyle{9 \over 2}\\ \rm{C} & \textstyle{1 \over 2} & 0 & 0 & -\textstyle{1 \over 2} & {z - \textstyle{9 \over 2}} \end{array} \right]$ X1=0表示可行解在x轴上；X4=0表示可行解在x1+2x2=9的直线上。那么，求得的可行解即表示这两条直线的交点，也是可行域的顶点，如图所示： 所以，通过选择不同的基变量，可以获得不同的可行域的顶点。 如何判断最优如前所述，基变量可由非基变量表示： $$x_i' = {C_i} \sum\limits_{j = m 1}^n {{m_{ij}}x_j'} (i = 1,2,...,m)$$ 目标函数z也可以完全由非基变量表示： $$z = {z_0} \sum\limits_{j = m 1}^n {{\sigma _j}x_j'}$$ 当达到最优解时，所有的$\sigma_j$应小于等于0。当存在j,$\sigma_j$&gt;0时，当前解不是最优解，为什么？ 当前的目标函数值为z0，其中所有的非基变量值均取0。由之前分析可知，$x_j’$=0代表可行域的某个边界，是$x_j’$的最小值。如果可行解逐步离开这个边界，$x_j’$会变大，因为$\sigma_j$&gt;0，显然目标函数的取值也会变大，所以当前解不是最优解。我们需要寻找新的基变量。 如何选择新的基变量如果存在多个$\sigma_j$&gt;0，选择最大的$\sigma_j$&gt;0对应的变量作为基变量，这表示目标函数随着$\sigma_j$的增加，增长的最快。 如何选择被替换的基变量假如我们选择非基变量$x_s’$作为下一轮的基变量，那么被替换基变量$x_j’$在下一轮中作为非基变量，等于0。选择$x_j’$的原则：替换后应该尽量使$x_s’$值最大（因为上面已分析过，目标函数会随着$x_s’$的增大而增大）。继续通过上面的例子来说明： $$\left[ {\begin{array}{*{20}{c}} {\rm{X}}&{{x_1}}&{{x_2}}&{{x_3}}&{{x_4}}&b\\ {}&2&1&1&0&{12}\\ {}&1&2&0&1&9\\ {\rm{C}}&1&1&0&0&z \end{array}} \right] \to \left[ {\begin{array}{*{20}{c}} {\rm{X}}&{{x_1}}&{{x_2}}&{{x_3}}&{{x_4}}&b\\ {}&{{\textstyle{3 \over 2}}}&0&1&{ - {\textstyle{1 \over 2}}}&{{\textstyle{{15} \over 2}}}\\ {}&{{\textstyle{1 \over 2}}}&1&0&{{\textstyle{1 \over 2}}}&{{\textstyle{9 \over 2}}}\\ {\rm{C}}&{{\textstyle{1 \over 2}}}&0&0&{ - {\textstyle{1 \over 2}}}&{z - {\textstyle{9 \over 2}}} \end{array}} \right]$$ 从最后一行可以看到，x1的系数为1/2&gt;0，所以选x2、x3为基变量并没有是目标函数达到最优。下一轮选取x1作为基变量，替换x2、x3中的某个变量。 第一行是符号第二行：若x1替换x3作为基变量，x3=0时，x1=(15/2)/(3/2)=5第三行：若x1替换x2作为基变量，x2=0时，x1=(9/2)/(1/2)=9显然，应该把x2作为非基变量。 终止条件当目标函数用非基变量的线性组合表示时，所有的系数均不大于0，则表示目标函数达到最优。 如果，有一个非基变量的系数为0，其他的均小于0，表示目标函数的最优解有无穷多个。这是因为目标函数的梯度与某一边界正交，在这个边界上，目标函数的取值均相等，且为最优。]]></content>
      <tags>
        <tag>算法</tag>
        <tag>最优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[获取当前程序路径Linux]]></title>
    <url>%2F2014%2F12%2F06%2F%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E7%A8%8B%E5%BA%8F%E8%B7%AF%E5%BE%84Linux%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718char * getCurrProPath() &#123; char * buf = new char[1024]; int n; n = readlink(&quot;/proc/self/exe&quot;, buf, 1024); if (n &lt; 0 || n &gt; 1024)&#123; printf(&quot;Cannot get current pro path!\n&quot;); delete buf; return NULL; &#125; for (int i = n; i &gt;=0; --i) &#123; if (buf[i] == &apos;\&apos;) &#123; buf[i] = &apos;\0&apos;; break; &#125; &#125; return buf;&#125;]]></content>
      <tags>
        <tag>linux</tag>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vsftpd用户修改密码]]></title>
    <url>%2F2014%2F12%2F06%2Fvsftpd%E7%94%A8%E6%88%B7%E4%BF%AE%E6%94%B9%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[创建ftp系统用户，防止用户通过ssh登陆，可以加上选项-s /sbin/nologin 如果想让用户自己修改密码，可以这样添加用户： useradd -g ftpusers -d /home/XXX -s /user/bin/passwd test 这样test用户通过ssh登陆后就显示修改密码的界面。 可以通过python程序的去添加用户，python的crypt模块实现对Unix密码的加密计算 123import os, cryptpwd = crypt.crypt(&quot;123456&quot;, &quot;ab&quot;)os.system(&quot;useradd -g %s -d %s -s /user/bin/passwd %s -p %s&quot; % (groupName, homePath, userName, pwd))]]></content>
      <tags>
        <tag>python</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[subprocess调用外部命令屏蔽输出]]></title>
    <url>%2F2014%2F12%2F06%2Fsubprocess%E8%B0%83%E7%94%A8%E5%A4%96%E9%83%A8%E5%91%BD%E4%BB%A4%E5%B1%8F%E8%94%BD%E8%BE%93%E5%87%BA%2F</url>
    <content type="text"><![CDATA[123import os, subprocessdevNull = open(os.devnull, &apos;w&apos;)p = subprocess.Popen(args, stdout = devNull) args为要执行的命令]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
</search>